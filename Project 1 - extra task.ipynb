{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description of notebook\n",
    "\n",
    "This notebook includes the code for the solution of the extra task specific to reproducing table III. For the analysis where the effects of varying the data uncertainty and quantity, both this notebook and the one for the main task were used. The variations of data were made with the notebook *Project 1 - data generator*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import sys\n",
    "from time import time\n",
    "import pickle\n",
    "\n",
    "# Third party libraries\n",
    "import emcee\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This parameter is just for us to control the names of saved figures. Please disregard it. :)\n",
    "task_type = 'basic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'basic_data.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-bdab1ffb9e98>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# This cell is for the redone analysis in the extra part of the project. Here, we just control what data is being fed to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# the functions and scripts in this notebook.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'{task_type}_data.pkl'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"rb\"\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Unpickles generated and pickled data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'basic_data.pkl'"
     ]
    }
   ],
   "source": [
    "# This cell is for the redone analysis in the extra part of the project. Here, we just control what data is being fed to\n",
    "# the functions and scripts in this notebook. \n",
    "data = pickle.load(open(f'{task_type}_data.pkl',\"rb\" ))  # Unpickles generated and pickled data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproduce Table III"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to sample our parameter space for our features $\\{a\\}$, for different values of $k$ and $k_{max}$, using both our uniform and naturaleness priors as defined in the basic tasks. However, the main difference is that we need to marginalize out the extra parameters for higher values of $k_{max}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy most of the code from the basic part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_data(file):\n",
    "    '''Load data given 'file' into a dictionary'''\n",
    "    d = {\n",
    "        \"x\": [],\n",
    "        \"d\": [],\n",
    "        \"sigma\": []\n",
    "    }\n",
    "    # Skip first two rows, which are the header:\n",
    "    with open(file) as f:\n",
    "        for idx,line in enumerate(f):\n",
    "            if idx < 3:\n",
    "                pass\n",
    "            else:\n",
    "                val = line.split()\n",
    "                d[\"x\"].append(np.float(val[0]))\n",
    "                d[\"d\"].append(np.float(val[1]))\n",
    "                d[\"sigma\"].append(np.float(val[2]))\n",
    "    # Cast to numpy arrays\n",
    "    d[\"x\"] = np.array(d[\"x\"])\n",
    "    d[\"d\"] = np.array(d[\"d\"])\n",
    "    d[\"sigma\"] = np.array(d[\"sigma\"])\n",
    "    return d\n",
    "\n",
    "\n",
    "def modular_model(a, x, kmax):\n",
    "    '''\n",
    "    Returns model of order kmax. a is a vector containing the model features.\n",
    "    Note the kmax+1 in the for loop. This is due to range being from 0 to\n",
    "    kmax-1.\n",
    "    '''\n",
    "    model = 0\n",
    "    for k in range(kmax+1):\n",
    "        model += a[k]*x**k\n",
    "    return model\n",
    "\n",
    "\n",
    "def log_uniform_prior(a):\n",
    "    '''\n",
    "    Flat, infinite uniform prior for a. This is used in this part of \n",
    "    the assignment to highlight the overfitting for higher model orders.\n",
    "    '''\n",
    "    return 0\n",
    "    \n",
    "\n",
    "def log_naturalness_prior(a, bar_a=5):\n",
    "    '''Naturaleness prior implemented according to equation 24 with bar(a)=5. This ensures'''\n",
    "    return -len(a)*np.log(np.sqrt(2*np.pi)*bar_a) - 1/2*(a.dot(a)/bar_a**2)\n",
    "\n",
    "\n",
    "def chi_squared(a, d, x, sigmas, kmax):\n",
    "    '''\n",
    "    Returns the chi squared measure for the datapoints d and x. The standard deviation is \n",
    "    assumed to be constant for all datapoints.\n",
    "    '''\n",
    "    chi_vec = (d-modular_model(a, x, kmax))/sigmas\n",
    "    return np.sum(chi_vec**2)\n",
    "\n",
    "\n",
    "def log_likelihood(a, d, x, sigmas, kmax):\n",
    "    '''\n",
    "    Returns log likelihood based on a Gaussian with di as the center values and \n",
    "    a standard deviation of sigma. a is the feature vector for our model.\n",
    "    '''\n",
    "    chi_sq = chi_squared(a, d, x, sigmas, kmax)\n",
    "    like = -np.sum(np.log(np.sqrt(2*np.pi)*sigmas)) - 1/2*chi_sq\n",
    "    return like\n",
    "\n",
    "\n",
    "def log_post_uniform(a,d,x,sigma, kmax):\n",
    "    '''The log posterior corresponding to the uniform prior'''\n",
    "    return log_likelihood(a,d,x,sigma,kmax) + log_uniform_prior(a)\n",
    "\n",
    "\n",
    "def log_post_natural(a,d,x,sigma, kmax, bar_a):\n",
    "    '''The log posterior corresponding to the naturalness prior'''\n",
    "    return log_likelihood(a,d,x,sigma,kmax) + log_naturalness_prior(a, bar_a=bar_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed test 1: True\n",
      "Passed test 2: False\n",
      "Passed test 3: True\n",
      "Passed test 4: [ True  True]\n",
      "Passed test 5: True\n",
      "Passed test 6: True\n",
      "Passed test 7: [ True  True]\n"
     ]
    }
   ],
   "source": [
    "# Unit test suite 1\n",
    "test1 = log_uniform_prior([-1,2,50]) == 0\n",
    "test2 = log_uniform_prior([-1,2,500]) == -np.inf\n",
    "test3 = -7.8651 == np.round(np.log((1/(np.sqrt(2*np.pi)*5))**3 * \\\n",
    "        np.exp(-(1+4+9)/(2*5**2))),4) == np.round(log_naturalness_prior(np.array([1,2,3]), 5),4) # Calculate expression exact and log\n",
    "                          \n",
    "print(f'Passed test 1: {test1}')\n",
    "print(f'Passed test 2: {test2}')\n",
    "print(f'Passed test 3: {test3}')\n",
    "\n",
    "# Unit test suite 2\n",
    "a = np.array([1,2,3,4])\n",
    "x = np.array([1,2])\n",
    "d = np.array([2,4])\n",
    "sigmas = np.array([2,4])\n",
    "kmax = len(a)-1  # Sanity check that the model still works in the basic task case\n",
    "a = np.array([1,2,3,4])\n",
    "x = np.array([1,2])\n",
    "d = np.array([2,4])\n",
    "sigmas = np.array([2,4])\n",
    "test4 = [10, 49] == modular_model(a,x,kmax)\n",
    "test5 = 142.5625==chi_squared(a,d,x,sigmas,kmax)\n",
    "exact_likelihood = np.prod(1/(np.sqrt(2*np.pi)*sigmas)) * np.exp(-chi_squared(a,d,x,sigmas,kmax)/2)\n",
    "test_likelihood = np.round(log_likelihood(np.array([1,2,3,4]), np.array([2,4]), np.array([1,2]), np.array([2,4]), kmax),4)\n",
    "test6 = np.round(np.log(exact_likelihood),4) == np.round(test_likelihood, 4) # exact calculation, and then log\n",
    "a = np.array([1,2,3,4,5,6,7])\n",
    "kmax = 6\n",
    "test7 = ([28, 769] == modular_model(a, x, kmax))\n",
    "print(f'Passed test 4: {test4}')\n",
    "print(f'Passed test 5: {test5}')\n",
    "print(f'Passed test 6: {test6}')\n",
    "print(f'Passed test 7: {test7}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1051a26329e649358b3f8f936a3adaaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmax: 0, k: 0\n",
      "Sampling time: 1.711735486984253 seconds.\n",
      "\n",
      "kmax: 1, k: 1\n",
      "Sampling time: 2.6064202785491943 seconds.\n",
      "\n",
      "kmax: 2, k: 2\n",
      "Sampling time: 3.276283025741577 seconds.\n",
      "\n",
      "kmax: 3, k: 2\n",
      "Sampling time: 4.181361198425293 seconds.\n",
      "\n",
      "kmax: 4, k: 2\n",
      "Sampling time: 5.250135898590088 seconds.\n",
      "\n",
      "kmax: 5, k: 2\n",
      "Sampling time: 6.414647340774536 seconds.\n",
      "\n",
      "kmax: 6, k: 2\n",
      "Sampling time: 7.775234222412109 seconds.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "file = 'D1_c_5.dat'\n",
    "data = load_data(file)\n",
    "\n",
    "# Define constants and data\n",
    "bar_a = 5\n",
    "x = data[\"x\"]\n",
    "d = data[\"d\"]\n",
    "sigmas = data[\"sigma\"]\n",
    "kmaxs = [i for i in range(0,6+1)]  # 0,1,2,3,4,5,6\n",
    "samples_dict = {}  # Define dict to save samples in\n",
    "\n",
    "for kmax in tqdm_notebook(kmaxs):\n",
    "    samples_dict[kmax] = {}\n",
    "    k = min(kmax,2)  # k+1 is the numbers of relevant features, so our model is at most of degree 2.\n",
    "    samples_dict[kmax][\"k\"] = k\n",
    "    print(f'kmax: {kmax}, k: {k}')\n",
    "    \n",
    "    # Define dimensions and walkers\n",
    "    ndim = kmax+1  # 0,1,...,kmax\n",
    "    nwalkers = ndim*2\n",
    "    # Initial guess\n",
    "    p0 = np.random.rand(ndim * nwalkers).reshape((nwalkers, ndim))\n",
    "\n",
    "\n",
    "    nburn = 200  # number of burn-in steps\n",
    "    nsamples = 2000  # number of final samples \n",
    "\n",
    "    # Additional arguments to our sampler: d, x, sigma and d,x,sigma, bar_a respectively\n",
    "    arglist_uniform = (d, x, sigmas, kmax)\n",
    "    arglist_natural = (d, x, sigmas, kmax, bar_a)\n",
    "\n",
    "    # Define samplers\n",
    "    sampler_uniform = emcee.EnsembleSampler(nwalkers, ndim, log_post_uniform, args=arglist_uniform)\n",
    "    sampler_natural = emcee.EnsembleSampler(nwalkers, ndim, log_post_natural, args=arglist_natural)\n",
    "    # Start sampler on posteriors. Use first few hundred iterations as burn-in. \n",
    "    t0 = time()  # Start time\n",
    "    sampler_uniform.run_mcmc(p0, nburn + nsamples)\n",
    "    sampler_natural.run_mcmc(p0, nburn + nsamples)\n",
    "    t1 = time()  # End time\n",
    "    print(f'Sampling time: {t1-t0} seconds.')\n",
    "    print()\n",
    "    \n",
    "    # Extract the samples and ignore burn in. Reshape to a single matrix\n",
    "    samples_uniform = sampler_uniform.chain[:,nburn:,:].reshape((-1,ndim))  # reshape to all samples per dim\n",
    "    samples_natural = sampler_natural.chain[:,nburn:,:].reshape((-1,ndim)) \n",
    "    \n",
    "    # Save samples\n",
    "    samples_dict[kmax][\"Uniform\"] = samples_uniform\n",
    "    samples_dict[kmax][\"Natural\"] = samples_natural"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, marginalize out all features higher than order $k=2$. We just do this by ignoring the other data corresponding to the higher order model parameters, since we are just interested in the number of times that we \"land\" on our relevant parameters anyway.\n",
    "\n",
    "Note that we show central values and 68% confidence interval: mean +- 1 std in the table (same as in the report). This is due to the posterior being Gaussian in both casses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13d84c754e4e40ec8c1e00dfab02e7a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e86fba11093d4390b804b554800f9d60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02a110e033e74e0f91c389f69a138096",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e10f269989a4362b6fe09034f2d8a6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88638b34cc8340f0be6b6fa93f041d45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cf664c29dd14dbcbb1b1c391be07154",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=24000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60103318c2f04a1e81a4f6e3879e792b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=28000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "******** Uniform ********\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>kmax</th>\n",
       "      <th>measure</th>\n",
       "      <th>a0</th>\n",
       "      <th>a1</th>\n",
       "      <th>a2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>66.68</td>\n",
       "      <td>0.48 +- 0.01</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.32</td>\n",
       "      <td>0.21 +- 0.02</td>\n",
       "      <td>2.5 +- 0.25</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.09</td>\n",
       "      <td>0.25 +- 0.02</td>\n",
       "      <td>1.6 +- 0.41</td>\n",
       "      <td>3.23 +- 1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2.16</td>\n",
       "      <td>0.27 +- 0.04</td>\n",
       "      <td>1.09 +- 1.05</td>\n",
       "      <td>7.2 +- 7.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2.13</td>\n",
       "      <td>0.32 +- 0.07</td>\n",
       "      <td>-1.25 +- 2.7</td>\n",
       "      <td>36.75 +- 32.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.52 +- 0.15</td>\n",
       "      <td>-12.31 +- 7.91</td>\n",
       "      <td>231.73 +- 135.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1.86</td>\n",
       "      <td>0.54 +- 0.26</td>\n",
       "      <td>-13.58 +- 15.64</td>\n",
       "      <td>256.71 +- 334.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   k  kmax measure            a0               a1                a2\n",
       "0  0     0   66.68  0.48 +- 0.01                                   \n",
       "1  1     1    3.32  0.21 +- 0.02      2.5 +- 0.25                  \n",
       "2  2     2    2.09  0.25 +- 0.02      1.6 +- 0.41       3.23 +- 1.3\n",
       "3  2     3    2.16  0.27 +- 0.04     1.09 +- 1.05       7.2 +- 7.77\n",
       "4  2     4    2.13  0.32 +- 0.07     -1.25 +- 2.7    36.75 +- 32.36\n",
       "5  2     5    1.75  0.52 +- 0.15   -12.31 +- 7.91  231.73 +- 135.55\n",
       "6  2     6    1.86  0.54 +- 0.26  -13.58 +- 15.64  256.71 +- 334.33"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******** Natural ********\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>kmax</th>\n",
       "      <th>measure</th>\n",
       "      <th>a0</th>\n",
       "      <th>a1</th>\n",
       "      <th>a2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.48 +- 0.01</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>692.12</td>\n",
       "      <td>0.21 +- 0.03</td>\n",
       "      <td>2.37 +- 0.39</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2983.5</td>\n",
       "      <td>0.25 +- 0.02</td>\n",
       "      <td>1.63 +- 0.37</td>\n",
       "      <td>3.13 +- 1.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2800.18</td>\n",
       "      <td>0.25 +- 0.02</td>\n",
       "      <td>1.6 +- 0.44</td>\n",
       "      <td>3.2 +- 2.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2851.46</td>\n",
       "      <td>0.25 +- 0.02</td>\n",
       "      <td>1.71 +- 0.46</td>\n",
       "      <td>2.56 +- 2.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2695.28</td>\n",
       "      <td>0.25 +- 0.03</td>\n",
       "      <td>1.66 +- 0.48</td>\n",
       "      <td>2.79 +- 2.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2617.1</td>\n",
       "      <td>0.24 +- 0.02</td>\n",
       "      <td>1.7 +- 0.45</td>\n",
       "      <td>2.87 +- 2.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   k  kmax  measure            a0            a1            a2\n",
       "0  0     0      0.0  0.48 +- 0.01                            \n",
       "1  1     1   692.12  0.21 +- 0.03  2.37 +- 0.39              \n",
       "2  2     2   2983.5  0.25 +- 0.02  1.63 +- 0.37  3.13 +- 1.24\n",
       "3  2     3  2800.18  0.25 +- 0.02   1.6 +- 0.44   3.2 +- 2.27\n",
       "4  2     4  2851.46  0.25 +- 0.02  1.71 +- 0.46  2.56 +- 2.45\n",
       "5  2     5  2695.28  0.25 +- 0.03  1.66 +- 0.48  2.79 +- 2.35\n",
       "6  2     6   2617.1  0.24 +- 0.02   1.7 +- 0.45  2.87 +- 2.33"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def calculate_feature_estimates(samples, prior_name, k, kmax):\n",
    "    a_mean = np.zeros((kmax+1))\n",
    "    a_std = np.zeros((kmax+1))\n",
    "    for i in range(kmax+1):\n",
    "        a_mean[i] = samples[:,i].mean()\n",
    "        a_std[i] =  samples[:,i].std()\n",
    "    if prior_name == 'Uniform':\n",
    "        # Calculate chi^2/dof for each \"model\", i.e. sets of {a_i}. Then take the mean. \n",
    "        chi_dof_arr = np.zeros((samples.shape[0],1))\n",
    "        for i in tqdm_notebook(range(samples.shape[0])):\n",
    "            # Iterate over all versions of the model \n",
    "            model = samples[i,:]\n",
    "            chi_dof_i = chi_squared(model, d, x, sigmas, kmax)/(len(x)-(k+1))  # len(x) - (k+1), since we compute (k+1) parameters in our model.\n",
    "            chi_dof_arr[i] = chi_dof_i\n",
    "        measure = chi_dof_arr.mean()\n",
    "    else:\n",
    "        # Integrate over all a to get evidence.\n",
    "        # Do this using Laplace's method, as described in the lecture notes (Learning from Data: Model selection).\n",
    "        cov = np.cov(samples.T)\n",
    "        if kmax == 0:\n",
    "            # Cast cov to a (1,1)-matrix for numpy.linalg.det to function.\n",
    "            cov = np.array(cov).reshape(1,1)\n",
    "        # Use the approximate expression for the evidence from the lecture notes (Learning from Data: Model selection).\n",
    "        # This approximate form is valid if the posterior is a Gaussian, which is the case here since our likelihood \n",
    "        # is a Gaussian and our priors are either Gaussian or uniform.\n",
    "        evidence = np.exp(log_post_natural(a_mean, d, x, sigmas, kmax, bar_a)) * np.sqrt((2*np.pi)**(kmax+1)/np.linalg.det(np.linalg.inv(cov)))\n",
    "        measure = evidence\n",
    "    return measure, a_mean[0:k+1], a_std[0:k+1]\n",
    "\n",
    "\n",
    "# Define dict to save table data in \n",
    "data_dict = {\n",
    "    \"Uniform\": {\n",
    "        \"k\": [],\n",
    "        \"kmax\": [],\n",
    "        \"measure\": [],\n",
    "        \"a0\": ['' for i in range(kmaxs[-1]+1)],\n",
    "        \"a1\": ['' for i in range(kmaxs[-1]+1)],\n",
    "        \"a2\": ['' for i in range(kmaxs[-1]+1)]\n",
    "    },\n",
    "    \"Natural\": {\n",
    "        \"k\": [],\n",
    "        \"kmax\": [],\n",
    "        \"measure\": [],\n",
    "        \"a0\": ['' for i in range(kmaxs[-1]+1)],\n",
    "        \"a1\": ['' for i in range(kmaxs[-1]+1)],\n",
    "        \"a2\": ['' for i in range(kmaxs[-1]+1)]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Generate table data, and populate the tables\n",
    "for kmax in samples_dict:\n",
    "    k = samples_dict[kmax][\"k\"]\n",
    "    for prior in data_dict:\n",
    "        samples = samples_dict[kmax][prior]\n",
    "        measure, a_mean, a_std = calculate_feature_estimates(samples, prior, k, kmax)\n",
    "        data_dict[prior][\"k\"].append(k)\n",
    "        data_dict[prior][\"kmax\"].append(kmax)\n",
    "        data_dict[prior][\"measure\"].append(str(np.round(measure,2)))\n",
    "        for idx, a_i in enumerate(a_mean):\n",
    "            data_dict[prior][\"a\"+str(idx)][kmax] = str(np.round(a_i,2)) + ' +- ' + str(np.round(a_std[idx],2))\n",
    "        \n",
    "uniform_dataframe = pd.DataFrame(data_dict[\"Uniform\"])\n",
    "natural_dataframe = pd.DataFrame(data_dict[\"Natural\"])\n",
    "\n",
    "# Show the tables\n",
    "print('******** Uniform ********')\n",
    "display(uniform_dataframe)\n",
    "print('******** Natural ********')\n",
    "display(natural_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
