{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import emcee \n",
    "import pandas as pd\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task c: Reproduce Table III"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to sample our parameter space for our features $\\{a\\}$, for different values of $k$ and $k_{max}$, using both our uniform and naturaleness priors as defined in the basic tasks. However, the main difference is that we need to marginalize out the extra parameters for higher values of $k_{max}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a modular model that generates features up to k_max: however we \n",
    "# then marginalize all larger k. \n",
    "def modular_model(a, x, kmax):\n",
    "    '''\n",
    "    Returns model of order kmax. a is a vector containing the model features.\n",
    "    Note the kmax+1 in the for loop. This is due to range being from 0 to\n",
    "    kmax-1.\n",
    "    '''\n",
    "    model = 0\n",
    "    for k in range(kmax+1):\n",
    "        model += a[k]*x**k\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\chi^2/\\text{dof}$ means the value of $\\chi^2$ per degree of freedom. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy most of the code from the basic part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': array([0.03183, 0.06366, 0.09549, 0.12732, 0.15915, 0.19099, 0.22282,\n",
       "        0.25465, 0.28648, 0.31831]),\n",
       " 'd': array([0.31694, 0.33844, 0.42142, 0.57709, 0.56218, 0.68851, 0.73625,\n",
       "        0.8727 , 1.0015 , 1.0684 ]),\n",
       " 'sigma': array([0.01585 , 0.01692 , 0.02107 , 0.02885 , 0.02811 , 0.03443 ,\n",
       "        0.03681 , 0.04364 , 0.050075, 0.05342 ])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load dataset\n",
    "def load_data(file):\n",
    "    d = {\n",
    "        \"x\": [],\n",
    "        \"d\": [],\n",
    "        \"sigma\": []\n",
    "    }\n",
    "    # Skip first two rows, which are the header:\n",
    "    with open(file) as f:\n",
    "        for idx,line in enumerate(f):\n",
    "            if idx < 3:\n",
    "                pass\n",
    "            else:\n",
    "                val = line.split()\n",
    "                d[\"x\"].append(np.float(val[0]))\n",
    "                d[\"d\"].append(np.float(val[1]))\n",
    "                d[\"sigma\"].append(np.float(val[2]))\n",
    "    # cast to numpy arrays\n",
    "    d[\"x\"] = np.array(d[\"x\"])\n",
    "    d[\"d\"] = np.array(d[\"d\"])\n",
    "    d[\"sigma\"] = np.array(d[\"sigma\"])\n",
    "    return d\n",
    "\n",
    "\n",
    "file = 'D1_c_5.dat'\n",
    "data = load_data(file)\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "def log_uniform_prior(a):\n",
    "    '''\n",
    "    Uniform prior, returns a log(1) if the values in a are in abs(a)<100. Note that this\n",
    "    prior is not normalized. We take care of this later.\n",
    "    '''\n",
    "    if np.all(np.abs(a)<=100):\n",
    "        return 0  # log(1)\n",
    "    else: \n",
    "        return -np.inf  # log(0)\n",
    "    \n",
    "\n",
    "def log_naturaleness_prior(a, bar_a=5):\n",
    "    '''Naturaleness prior implemented according to equation 24 with bar(a)=5. This ensures'''\n",
    "    return -len(a)*np.log(np.sqrt(2*np.pi)*bar_a) - 1/2*(a.dot(a)/bar_a**2)\n",
    "\n",
    "# Tests \n",
    "print(0 == log_uniform_prior([-1,2,50]))\n",
    "print(-np.inf == log_uniform_prior([-1,2,500]))\n",
    "print(-7.8651 == np.round(np.log((1/(np.sqrt(2*np.pi)*5))**3 * np.exp(-(1+4+9)/(2*5**2))),4) == np.round(log_naturaleness_prior(np.array([1,2,3]), 5),4))  # Calculate expression exact and log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model kmax=3: [ True  True]\n",
      "chi_squared: True\n",
      "log likelihood: True\n",
      "Model kmax=6: [ True  True]\n"
     ]
    }
   ],
   "source": [
    "def chi_squared(a, d, x, sigmas, kmax):\n",
    "    '''\n",
    "    Returns the chi squared measure for the datapoints d and x. The standard deviation is \n",
    "    assumed to be constant for all datapoints.\n",
    "    '''\n",
    "    chi_vec = (d-modular_model(a, x, kmax))/sigmas\n",
    "    return np.sum(chi_vec**2)\n",
    "\n",
    "\n",
    "def log_likelihood(a, d, x, sigmas, kmax):\n",
    "    '''\n",
    "    Returns log likelihood based on a Gaussian with di as the center values and \n",
    "    a standard deviation of sigma. a is the feature vector for our model.\n",
    "    '''\n",
    "    chi_sq = chi_squared(a, d, x, sigmas, kmax)\n",
    "    like = -np.sum(np.log(np.sqrt(2*np.pi)*sigmas)) - 1/2*chi_sq\n",
    "    return like\n",
    "\n",
    "\n",
    "# Tests\n",
    "a = np.array([1,2,3,4])\n",
    "x = np.array([1,2])\n",
    "d = np.array([2,4])\n",
    "sigmas = np.array([2,4])\n",
    "kmax = len(a)-1  # Sanity check that the model still works in the basic task case\n",
    "print(f'Model kmax={kmax}: {[10, 49] == modular_model(a,x, kmax)}')\n",
    "print(f'chi_squared: {142.5625==chi_squared(a,d,x,sigmas, kmax)}')\n",
    "exact_likelihood = np.prod(1/(np.sqrt(2*np.pi)*sigmas)) * np.exp(-chi_squared(a,d,x,sigmas, kmax)/2)\n",
    "print(f'log likelihood: {np.round(np.log(exact_likelihood),4) == np.round(log_likelihood(a, d, x, sigmas, kmax),4)}')  # exact calculation, and then log\n",
    "# Also test in kmax = 6 case\n",
    "a = np.array([1,2,3,4,5,6,7])\n",
    "kmax = 6\n",
    "print(f'Model kmax={kmax}: {[28, 769] == modular_model(a, x, kmax)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ok our new model passes this sanity check. All of our tests from the basic problem returns ok with the new modular model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_post_uniform(a,d,x,sigma, kmax):\n",
    "    return log_likelihood(a,d,x,sigma,kmax) + log_uniform_prior(a)\n",
    "\n",
    "\n",
    "def log_post_natural(a,d,x,sigma, kmax, bar_a):\n",
    "    return log_likelihood(a,d,x,sigma,kmax) + log_naturaleness_prior(a, bar_a=bar_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmax: 0, k: 0\n",
      "Sampling time: 16.07931900024414 seconds.\n",
      "\n",
      "kmax: 1, k: 1\n",
      "Sampling time: 23.941835165023804 seconds.\n",
      "\n",
      "kmax: 2, k: 2\n",
      "Sampling time: 30.69278597831726 seconds.\n",
      "\n",
      "kmax: 3, k: 2\n",
      "Sampling time: 39.95971989631653 seconds.\n",
      "\n",
      "kmax: 4, k: 2\n",
      "Sampling time: 50.859737396240234 seconds.\n",
      "\n",
      "kmax: 5, k: 2\n",
      "Sampling time: 62.648125886917114 seconds.\n",
      "\n",
      "kmax: 6, k: 2\n",
      "Sampling time: 75.92414617538452 seconds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sampling\n",
    "\n",
    "# Define constants and data\n",
    "bar_a = 5\n",
    "x = data[\"x\"]\n",
    "d = data[\"d\"]\n",
    "sigmas = data[\"sigma\"]\n",
    "kmaxs = [i for i in range(0,6+1)]  # 0,1,2,3,4,5,6\n",
    "samples_dict = {}  # Define dict to save samples in\n",
    "for kmax in kmaxs:\n",
    "    samples_dict[kmax] = {}\n",
    "    k = min(kmax,2)  # k+1 is the numbers of relevant features, so our model is at most of degree 2.\n",
    "    samples_dict[kmax][\"k\"] = k\n",
    "    print(f'kmax: {kmax}, k: {k}')\n",
    "    \n",
    "    # Define dimensions and walkers\n",
    "    ndim = kmax+1  # 0,1,...,kmax\n",
    "    nwalkers = ndim*2\n",
    "    # Initial guess\n",
    "    p0 = np.random.rand(ndim * nwalkers).reshape((nwalkers, ndim))\n",
    "\n",
    "\n",
    "    nburn = 200  # nbr of burning steps\n",
    "    nsamples = 20000  # nbr of final samples \n",
    "\n",
    "    # additional arguments to our sampler: d, x, sigma and d,x,sigma, bar_a respectively\n",
    "    arglist_uniform = (d, x, sigmas, kmax)\n",
    "    arglist_natural = (d, x, sigmas, kmax, bar_a)\n",
    "\n",
    "    # Define samplers\n",
    "    sampler_uniform = emcee.EnsembleSampler(nwalkers, ndim, log_post_uniform, args=arglist_uniform)\n",
    "    sampler_natural = emcee.EnsembleSampler(nwalkers, ndim, log_post_natural, args=arglist_natural)\n",
    "    # Start sampler on posteriors. Use first few hundred iterations as burn in. \n",
    "    t0 = time()  # start time\n",
    "    sampler_uniform.run_mcmc(p0, nburn + nsamples)\n",
    "    sampler_natural.run_mcmc(p0, nburn + nsamples)\n",
    "    t1 = time()  # end time\n",
    "    print(f'Sampling time: {t1-t0} seconds.')\n",
    "    print()\n",
    "    \n",
    "    samples_uniform = sampler_uniform.chain[:,nburn:,:].reshape((-1,ndim))  # reshape to all samples per dim\n",
    "    samples_natural = sampler_natural.chain[:,nburn:,:].reshape((-1,ndim)) \n",
    "    \n",
    "    # Save samples\n",
    "    samples_dict[kmax][\"Uniform\"] = samples_uniform\n",
    "    samples_dict[kmax][\"Natural\"] = samples_natural"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, marginalize out all features higher than order k=2, and compute the mean for our feature. We just do this by ignoring the other data corresponding to the higher features, since we are just interested in the number of times that we \"land\" on our relevant features anyway.\n",
    "\n",
    "We show central values and 68% confidence interval: mean +- 1 std for the Gaussian posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** Uniform **********\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>kmax</th>\n",
       "      <th>measure</th>\n",
       "      <th>a0</th>\n",
       "      <th>a1</th>\n",
       "      <th>a2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>599.01</td>\n",
       "      <td>0.48 +- 0.01</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.94</td>\n",
       "      <td>0.2 +- 0.01</td>\n",
       "      <td>2.56 +- 0.11</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.83</td>\n",
       "      <td>0.25 +- 0.02</td>\n",
       "      <td>1.58 +- 0.4</td>\n",
       "      <td>3.29 +- 1.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>29.65</td>\n",
       "      <td>0.27 +- 0.04</td>\n",
       "      <td>1.01 +- 1.11</td>\n",
       "      <td>7.77 +- 8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>79.17</td>\n",
       "      <td>0.27 +- 0.04</td>\n",
       "      <td>0.8 +- 1.22</td>\n",
       "      <td>10.26 +- 10.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>81.12</td>\n",
       "      <td>0.27 +- 0.04</td>\n",
       "      <td>0.82 +- 1.27</td>\n",
       "      <td>10.27 +- 11.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>80.84</td>\n",
       "      <td>0.27 +- 0.04</td>\n",
       "      <td>0.79 +- 1.26</td>\n",
       "      <td>10.35 +- 11.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   k  kmax measure            a0            a1              a2\n",
       "0  0     0  599.01  0.48 +- 0.01                              \n",
       "1  1     1    8.94   0.2 +- 0.01  2.56 +- 0.11                \n",
       "2  2     2    3.83  0.25 +- 0.02   1.58 +- 0.4    3.29 +- 1.31\n",
       "3  2     3   29.65  0.27 +- 0.04  1.01 +- 1.11     7.77 +- 8.2\n",
       "4  2     4   79.17  0.27 +- 0.04   0.8 +- 1.22  10.26 +- 10.91\n",
       "5  2     5   81.12  0.27 +- 0.04  0.82 +- 1.27  10.27 +- 11.51\n",
       "6  2     6   80.84  0.27 +- 0.04  0.79 +- 1.26  10.35 +- 11.46"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** Natural **********\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>kmax</th>\n",
       "      <th>measure</th>\n",
       "      <th>a0</th>\n",
       "      <th>a1</th>\n",
       "      <th>a2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.48 +- 0.01</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19783637.34</td>\n",
       "      <td>0.2 +- 0.01</td>\n",
       "      <td>2.55 +- 0.11</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>477112464.59</td>\n",
       "      <td>0.25 +- 0.02</td>\n",
       "      <td>1.63 +- 0.4</td>\n",
       "      <td>3.11 +- 1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>436966712.69</td>\n",
       "      <td>0.25 +- 0.02</td>\n",
       "      <td>1.64 +- 0.46</td>\n",
       "      <td>2.99 +- 2.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>453772963.14</td>\n",
       "      <td>0.25 +- 0.02</td>\n",
       "      <td>1.64 +- 0.46</td>\n",
       "      <td>3.01 +- 2.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>455564664.62</td>\n",
       "      <td>0.25 +- 0.02</td>\n",
       "      <td>1.64 +- 0.47</td>\n",
       "      <td>3.04 +- 2.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>392170087.05</td>\n",
       "      <td>0.25 +- 0.02</td>\n",
       "      <td>1.66 +- 0.47</td>\n",
       "      <td>2.87 +- 2.39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   k  kmax       measure            a0            a1            a2\n",
       "0  0     0           0.0  0.48 +- 0.01                            \n",
       "1  1     1   19783637.34   0.2 +- 0.01  2.55 +- 0.11              \n",
       "2  2     2  477112464.59  0.25 +- 0.02   1.63 +- 0.4   3.11 +- 1.3\n",
       "3  2     3  436966712.69  0.25 +- 0.02  1.64 +- 0.46  2.99 +- 2.37\n",
       "4  2     4  453772963.14  0.25 +- 0.02  1.64 +- 0.46  3.01 +- 2.38\n",
       "5  2     5  455564664.62  0.25 +- 0.02  1.64 +- 0.47  3.04 +- 2.43\n",
       "6  2     6  392170087.05  0.25 +- 0.02  1.66 +- 0.47  2.87 +- 2.39"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def calculate_feature_estimates(samples, prior_name, k, kmax):\n",
    "    a_mean = np.zeros((k+1))\n",
    "    a_std = np.zeros((k+1))\n",
    "    for i in range(k+1):\n",
    "        a_mean[i] = samples[:,i].mean()\n",
    "        a_std[i] =  samples[:,i].std()\n",
    "    if prior_name == 'Uniform':\n",
    "        # TODO should I send in k here? Our model only consists of features up to k, since we marginalize the rest.\n",
    "        chi_dof = chi_squared(a_mean, d, x, sigmas, k)/(k+1)  # k features in our model and k dof (?)\n",
    "        measure = chi_dof\n",
    "    else:\n",
    "        # TODO same as above\n",
    "        evidence = np.exp(log_likelihood(a_mean, d, x, sigmas, k))\n",
    "        measure = evidence\n",
    "    return measure, a_mean, a_std\n",
    "\n",
    "\n",
    "data_dict = {\n",
    "    \"Uniform\": {\n",
    "        \"k\": [],\n",
    "        \"kmax\": [],\n",
    "        \"measure\": [],\n",
    "        \"a0\": ['' for i in range(kmaxs[-1]+1)],\n",
    "        \"a1\": ['' for i in range(kmaxs[-1]+1)],\n",
    "        \"a2\": ['' for i in range(kmaxs[-1]+1)]\n",
    "    },\n",
    "    \"Natural\": {\n",
    "        \"k\": [],\n",
    "        \"kmax\": [],\n",
    "        \"measure\": [],\n",
    "        \"a0\": ['' for i in range(kmaxs[-1]+1)],\n",
    "        \"a1\": ['' for i in range(kmaxs[-1]+1)],\n",
    "        \"a2\": ['' for i in range(kmaxs[-1]+1)]\n",
    "    }\n",
    "}\n",
    "for kmax in samples_dict:\n",
    "    k = samples_dict[kmax][\"k\"]\n",
    "    for prior in data_dict:\n",
    "        samples = samples_dict[kmax][prior]\n",
    "        measure, a_mean, a_std = calculate_feature_estimates(samples, prior, k, kmax)\n",
    "        data_dict[prior][\"k\"].append(k)\n",
    "        data_dict[prior][\"kmax\"].append(kmax)\n",
    "        data_dict[prior][\"measure\"].append(str(np.round(measure,2)))\n",
    "        for idx, a_i in enumerate(a_mean):\n",
    "            data_dict[prior][\"a\"+str(idx)][kmax] = str(np.round(a_i,2)) + ' +- ' + str(np.round(a_std[idx],2))\n",
    "        \n",
    "uniform_dataframe = pd.DataFrame(data_dict[\"Uniform\"])\n",
    "natural_dataframe = pd.DataFrame(data_dict[\"Natural\"])\n",
    "print('********** Uniform **********')\n",
    "display(uniform_dataframe)\n",
    "print('********** Natural **********')\n",
    "display(natural_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Generate new data and repeat analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return none if invalid x: True\n",
      "Return values if ok x: [ True  True]\n"
     ]
    }
   ],
   "source": [
    "# Generate new data using polynomial\n",
    "def exact_data(x):\n",
    "    '''Returns exact data using the given function'''\n",
    "    if (np.abs(x) <= 1/np.pi).all() and (x>0).all():\n",
    "        g = (1/2+np.tan(np.pi/2*x))**2\n",
    "        return g\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Tests\n",
    "x_f = np.array([0.1, 0.4])\n",
    "x_ok = np.array([0.1, 0.2])\n",
    "g_f = exact_data(x_f)\n",
    "g_ok = np.round(exact_data(x_ok),4)\n",
    "print(f'Return none if invalid x: {None == g_f}')\n",
    "print(f'Return values if ok x: {[0.4335, 0.6805] == g_ok}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.26595604 0.27072466 0.27553656 0.28039196 0.28529111 0.29023425\n",
      " 0.29522163 0.30025351 0.30533016 0.31045186 0.31561889 0.32083153\n",
      " 0.3260901  0.3313949  0.33674623 0.34214443 0.34758983 0.35308276\n",
      " 0.35862357 0.36421263 0.36985028 0.37553692 0.38127291 0.38705865\n",
      " 0.39289454 0.39878099 0.40471841 0.41070724 0.41674791 0.42284086\n",
      " 0.42898655 0.43518545 0.44143803 0.44774478 0.45410619 0.46052276\n",
      " 0.46699502 0.47352349 0.4801087  0.48675121 0.49345158 0.50021037\n",
      " 0.50702817 0.51390558 0.52084319 0.52784162 0.53490152 0.54202351\n",
      " 0.54920825 0.55645641 0.56376868 0.57114575 0.57858831 0.58609711\n",
      " 0.59367286 0.60131633 0.60902827 0.61680947 0.62466072 0.63258283\n",
      " 0.64057662 0.64864294 0.65678264 0.6649966  0.67328571 0.68165088\n",
      " 0.69009303 0.6986131  0.70721207 0.7158909  0.72465061 0.7334922\n",
      " 0.74241672 0.75142523 0.7605188  0.76969853 0.77896556 0.78832102\n",
      " 0.79776607 0.80730192 0.81692977 0.82665085 0.83646643 0.8463778\n",
      " 0.85638627 0.86649317 0.87669986 0.88700775 0.89741825 0.9079328\n",
      " 0.91855288 0.92928001 0.94011571 0.95106156 0.96211915 0.97329012\n",
      " 0.98457614 0.9959789  1.00750014 1.01914163]\n",
      "[0.28755626 0.26244378 0.26826003 0.26534937 0.29763577 0.25683498\n",
      " 0.32097693 0.28882576 0.31020077 0.30658098 0.33869233 0.28778363\n",
      " 0.32083325 0.32503121 0.35583586 0.32332835 0.34459311 0.33758492\n",
      " 0.35938051 0.37482606 0.34949707 0.39703122 0.39846051 0.39678339\n",
      " 0.41059161 0.38514811 0.40223162 0.39149088 0.41116582 0.43405366\n",
      " 0.4141509  0.42655239 0.42627083 0.42882296 0.43886534 0.46023114\n",
      " 0.4409061  0.47907355 0.51995298 0.50481076 0.4887185  0.47801031\n",
      " 0.48808666 0.55739367 0.52216633 0.51102998 0.54000756 0.59894289\n",
      " 0.55250786 0.57362875 0.57223001 0.56108645 0.54553593 0.57585967\n",
      " 0.58747212 0.61895363 0.6345765  0.6455251  0.63358048 0.66057908\n",
      " 0.61641414 0.68927614 0.67362681 0.65508506 0.68973132 0.6790752\n",
      " 0.7291395  0.7517013  0.78449533 0.66590395 0.67232671 0.71499111\n",
      " 0.74835743 0.784344   0.77252111 0.69187427 0.76703944 0.82095651\n",
      " 0.80694416 0.83806057 0.80784844 0.81835301 0.84426905 0.86373073\n",
      " 0.86487733 0.87164918 0.84730139 0.90375285 0.90288448 0.95920757\n",
      " 0.97361636 0.93788312 0.92247515 0.92068796 0.98249175 0.97705384\n",
      " 0.96764863 0.99814998 0.97626759 1.05471131]\n"
     ]
    }
   ],
   "source": [
    "# Add higher noise to data\n",
    "np.random.seed(1)  # Fix seed to get same random variables every time from generator - should not make a difference!\n",
    "def add_noise(g, c):\n",
    "    random_vector = np.random.normal(loc=0, scale=1, size=len(g))\n",
    "    return g*(1+c*random_vector)\n",
    "x=np.linspace(0.01, 0.3,100)\n",
    "g = exact_data(x)\n",
    "print(add_noise(g, 0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
